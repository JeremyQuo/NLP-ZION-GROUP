{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "l7X4R-0NlHZQ"
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Preliminaries\n",
    "import torchtext\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "\n",
    "# Models\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Training\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-] Training Dataset: std_data/Race/middle/train.csv\n"
     ]
    }
   ],
   "source": [
    "from Config import Config\n",
    "from utils import *\n",
    "from model import BERT\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gM8I87lOlHZV",
    "outputId": "8aa29e02-e3e2-4364-a76d-772af4712ed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# # Parameters\n",
    "source_folder = '/content/drive/MyDrive/PolyU Master/NLP/EmotionClassifier/data'\n",
    "destination_folder = '/content/drive/MyDrive/PolyU Master/NLP/EmotionClassifier/Model'\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sqH6ic6AlHZW",
    "outputId": "751ff725-5041-4e5c-bd2d-61b6d0b1a522"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Model parameter\n",
    "MAX_SEQ_LEN = config.MAX_SEQ_LEN\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
    "\n",
    "\n",
    "\n",
    "# TabularDataset\n",
    "train, valid = prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eCmVcjIalHZX",
    "outputId": "53f82e00-ec7a-4f42-e8fd-c0058a180d4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "load_checkpoint() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cc41f71d6392>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBERT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mload_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestination_folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/model.pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: load_checkpoint() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "best_model = BERT().to(device)\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cGD6_LP2lHZX",
    "outputId": "f9e7e1c1-9731-4d69-dac8-d1f8eda586e5"
   },
   "outputs": [],
   "source": [
    "model = best_model\n",
    "test_loader = test_iter\n",
    "#Evaluate\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "        for ( labels, A,B,C,D), _ in valid_loader:\n",
    "            labels = labels.type(torch.LongTensor)           \n",
    "            labels = labels.to(device)\n",
    "\n",
    "            model_input = torch.stack([A,B,C,D],1)\n",
    "            model_input = model_input.type(torch.LongTensor).to(device)\n",
    "\n",
    "            output = model(model_input, labels)\n",
    "\n",
    "            _, output = output\n",
    "            y_pred.extend(torch.argmax(output, 1).tolist())\n",
    "            y_true.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x8aM9G0dlHZY",
    "outputId": "8a5c9dfa-7881-418b-b343-7c0772b2d3d8"
   },
   "outputs": [],
   "source": [
    "print('Classification Report:')\n",
    "print(classification_report(le.inverse_transform(y_true), le.inverse_transform(y_pred), labels=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "1Mh-0j_blHZY",
    "outputId": "903279b4-14d5-434e-b2cf-664f7294fc89"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(le.inverse_transform(y_true), le.inverse_transform(y_pred), labels=le.classes_)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "ax.xaxis.set_ticklabels(le.classes_)\n",
    "ax.yaxis.set_ticklabels(le.classes_)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Evaluate.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

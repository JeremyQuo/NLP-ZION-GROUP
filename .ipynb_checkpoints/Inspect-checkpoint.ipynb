{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>work_times</th>\n",
       "      <th>article</th>\n",
       "      <th>question_type</th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mc160.train.0</td>\n",
       "      <td>1844466225</td>\n",
       "      <td>2383</td>\n",
       "      <td>Tom had to fix some things around the house. H...</td>\n",
       "      <td>multiple</td>\n",
       "      <td>What was the hardest thing for Tom and his fri...</td>\n",
       "      <td>Door</td>\n",
       "      <td>House</td>\n",
       "      <td>Window</td>\n",
       "      <td>Toilet</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mc160.train.0</td>\n",
       "      <td>1844466225</td>\n",
       "      <td>2383</td>\n",
       "      <td>Tom had to fix some things around the house. H...</td>\n",
       "      <td>one</td>\n",
       "      <td>What did Tom need to fix first?</td>\n",
       "      <td>Door</td>\n",
       "      <td>House</td>\n",
       "      <td>Window</td>\n",
       "      <td>Toilet</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mc160.train.0</td>\n",
       "      <td>1844466225</td>\n",
       "      <td>2383</td>\n",
       "      <td>Tom had to fix some things around the house. H...</td>\n",
       "      <td>multiple</td>\n",
       "      <td>Jim didn't bring which person with him?</td>\n",
       "      <td>Jim</td>\n",
       "      <td>Dolly</td>\n",
       "      <td>Molly</td>\n",
       "      <td>Holly</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mc160.train.0</td>\n",
       "      <td>1844466225</td>\n",
       "      <td>2383</td>\n",
       "      <td>Tom had to fix some things around the house. H...</td>\n",
       "      <td>one</td>\n",
       "      <td>Who was Tom's best friend?</td>\n",
       "      <td>Molly</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Jim</td>\n",
       "      <td>Dolly</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mc160.train.1</td>\n",
       "      <td>88979267</td>\n",
       "      <td>12668</td>\n",
       "      <td>Lisa has a pet cat named Whiskers. Whiskers is...</td>\n",
       "      <td>multiple</td>\n",
       "      <td>What day is Whisker's Birthday?</td>\n",
       "      <td>Today</td>\n",
       "      <td>Last year</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id      author  work_times  \\\n",
       "0  mc160.train.0  1844466225        2383   \n",
       "1  mc160.train.0  1844466225        2383   \n",
       "2  mc160.train.0  1844466225        2383   \n",
       "3  mc160.train.0  1844466225        2383   \n",
       "4  mc160.train.1    88979267       12668   \n",
       "\n",
       "                                             article question_type  \\\n",
       "0  Tom had to fix some things around the house. H...      multiple   \n",
       "1  Tom had to fix some things around the house. H...           one   \n",
       "2  Tom had to fix some things around the house. H...      multiple   \n",
       "3  Tom had to fix some things around the house. H...           one   \n",
       "4  Lisa has a pet cat named Whiskers. Whiskers is...      multiple   \n",
       "\n",
       "                                            question      A          B  \\\n",
       "0  What was the hardest thing for Tom and his fri...   Door      House   \n",
       "1                    What did Tom need to fix first?   Door      House   \n",
       "2            Jim didn't bring which person with him?    Jim      Dolly   \n",
       "3                         Who was Tom's best friend?  Molly      Holly   \n",
       "4                    What day is Whisker's Birthday?  Today  Last year   \n",
       "\n",
       "        C         D answer  \n",
       "0  Window    Toilet      C  \n",
       "1  Window    Toilet      D  \n",
       "2   Molly     Holly      B  \n",
       "3     Jim     Dolly      C  \n",
       "4  Friday  Saturday      D  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('std_data/MCTest/mc160/mc160.train.csv',index_col=0)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "gold = le.fit_transform(df_train['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name            module\n",
      "----------------------\n",
      "bert:embeddings\n",
      "bert:encoder\n",
      "bert:pooler\n",
      "dropout         Dropout(p=0.1, inplace=False)\n",
      "classifier      Linear(in_features=768, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertConfig, CONFIG_NAME, WEIGHTS_NAME,BertForMultipleChoice\n",
    "from torch.nn.modules import Softmax\n",
    "\n",
    "pretrained_model = \"bert-base-uncased\"\n",
    "\n",
    "config = BertConfig.from_pretrained(\n",
    "            pretrained_model,\n",
    "            num_labels=4\n",
    ")\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "model = BertForMultipleChoice.from_pretrained(pretrained_model,config=config)\n",
    "\n",
    "# high-level 顯示此模型裡的 modules\n",
    "print(\"\"\"\n",
    "name            module\n",
    "----------------------\"\"\")\n",
    "for name, module in model.named_children():\n",
    "    if name == \"bert\":\n",
    "        for n, _ in module.named_children():\n",
    "            print(f\"{name}:{n}\")\n",
    "    else:\n",
    "        print(\"{:15} {}\".format(name, module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)\n",
    "#_, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "#print(\"classification acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = df_train.sample(frac=0.01, random_state=9527)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train[['article','question','answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "predrictions = []\n",
    "for i in range(10):\n",
    "    try:\n",
    "        fact_sent = train_df['article'][i]\n",
    "        answers = [train_df[opt][i] for opt in ['A','B','C','D']]\n",
    "        labels = torch.tensor(0).unsqueeze(0)\n",
    "        fact_sent = [fact_sent for _ in range(len(answers)) ]\n",
    "        \n",
    "        encoding = tokenizer(list(zip(fact_sent, answers)), return_tensors='pt', padding=True)\n",
    "        outputs = model(**{k: v.unsqueeze(0) for k,v in encoding.items()}, labels=labels)\n",
    "        loss, logits = outputs[:2]\n",
    "\n",
    "        predrictions.append(torch.max(logits.data.indices.tolist()[0], 1))\n",
    "\n",
    "    except:\n",
    "        predrictions.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[102, 101]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize('[SEP][CLS]')\n",
    "tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starts Traning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminaries\n",
    "import torchtext\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "\n",
    "# Models\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameter\n",
    "MAX_SEQ_LEN = 128\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
    "\n",
    "# Fields\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
    "text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n",
    "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
    "fields = [('label', label_field), ('article_question', text_field), ('option', text_field)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.example.Example at 0x126363bb0>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX = {}\n",
    "labels = train_df['answer']\n",
    "options = [train_df[i] for i in [\"A\",\"B\",\"C\",\"D\"]]\n",
    "article_question = \"[CLS]\"+train_df['article']+'[SEP]' +train_df['question']\n",
    "torchtext.data.Example.fromlist([article_question],fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = BucketIterator(train, batch_size=16, sort_key=lambda x: len(x.text),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=16, sort_key=lambda x: len(x.text),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "test_iter = Iterator(test, batch_size=16, device=device, train=False, shuffle=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
